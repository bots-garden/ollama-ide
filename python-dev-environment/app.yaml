services:
  # GenAI application
  python-dev-environment:
    entrypoint: ["code-server", "--auth", "none", "--host", "0.0.0.0", "--port", "${PYTHON_DEV_ENV_HTTP_PORT}", "/python-dev-environment/workspace"]
    environment: &environment-python
      - PYTHON_DEV_ENV_HTTP_PORT=${PYTHON_DEV_ENV_HTTP_PORT}
      - XDG_DATA_HOME=/python-dev-environment/.config
      # Ollama is running in a containerr without GPU
      #- OLLAMA_BASE_URL=http://ollama-service:11434
      # Access to the hosted Ollama on MacBook M1
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    build: &build-python
      context: .
      dockerfile: Dockerfile    
      args:
        - CODER_VERSION=${CODER_VERSION}
        - CODER_ARCH=${CODER_ARCH}
    depends_on:
      ollama-service:
        condition: service_started
    #platform: linux/${LINUX_ARCH}
    volumes: &volumes-python
      - ../python-dev-environment:/python-dev-environment
    ports:
      - ${PYTHON_DEV_ENV_HTTP_PORT}:${PYTHON_DEV_ENV_HTTP_PORT}
      # Streamlit
      - 8501:8501

  python-dev-environment-tasks:
    depends_on:
      - python-dev-environment
    entrypoint: ["/python-dev-environment/.tasks/init.sh"]
    environment: *environment-python
    build: *build-python  
    #platform: linux/${LINUX_ARCH}
    volumes: *volumes-python
